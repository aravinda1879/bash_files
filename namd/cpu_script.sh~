#! /bin/bash
source ../namd_variables.sh
cat << EOF > script_cpu.sh
#!/bin/bash
#SBATCH --job-name=${infile}
#SBATCH --output=gpuMemTest.out
#SBATCH --error=gpuMemTest.err
#SBATCH --ntasks=1
#SBATCH --nodes=$num_nodes
#SBATCH --cpus-per-task=${num_cpu}
#SBATCH --ntasks-per-socket=1
#SBATCH --distribution=block:block
#SBATCH --time=4-00:00:00
#SBATCH --mem-per-cpu=2gb
#SBATCH --mail-type=none
#SBATCH --mail-user=some_user@some_domain.com
##SBATCH --account=your_account
##SBATCH --qos=colina-b
#SBATCH --partition=hpg2-compute
##SBATCH --gres=gpu:tesla:${num_gpu}
module load intel/2017  openmpi/2.0.1 namd/2.12



srun --mpi=pmix -N${num_nodes} -n${num_cpu} namd2 +setcpuaffinity  ${conf_min1_f} > ${infile}_wb_min_1.log
srun --mpi=pmix -N${num_nodes} -n${num_cpu} namd2 +setcpuaffinity  ${conf_min2_f} > ${infile}_wb_min_2.log
module load vmd
vmd -dispdev text -eofexit < $tcl_f4 > output_vmd5.log
srun --mpi=pmix -N${num_nodes} -n${num_cpu} namd2 +setcpuaffinity  ${conf_heat_eq_f} > ${infile}_wb_eq_heat.log
srun --mpi=pmix -N${num_nodes} -n${num_cpu} namd2 +setcpuaffinity  ${conf_pro_f} > ${infile}_wb_md.log
EOF
for i in `seq 2 $run_repeat`;
do
cat << EOF >> script_cpu.sh
srun --mpi=pmix -N${num_nodes} -n${num_cpu} namd2 +setcpuaffinity  ${conf_pro_f%1.conf}$i.conf > ${infile}_wb_md${i}.log
EOF
done    
